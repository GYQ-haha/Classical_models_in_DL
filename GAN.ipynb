{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5b46d29",
   "metadata": {},
   "source": [
    "产生与MINST数据集中与真实图片**风格**一致的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d7db66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/100],d_loss:0.144313,g_loss:3.486530 D real: 0.967989,D fake: 0.100307\n",
      "Epoch[0/100],d_loss:0.031358,g_loss:4.446863 D real: 0.997865,D fake: 0.028687\n",
      "Epoch[0/100],d_loss:0.185937,g_loss:4.918364 D real: 0.962547,D fake: 0.127346\n",
      "Epoch[0/100],d_loss:0.062624,g_loss:6.851132 D real: 0.988994,D fake: 0.045991\n",
      "Epoch[1/100],d_loss:0.039476,g_loss:4.500678 D real: 0.994901,D fake: 0.033383\n",
      "Epoch[1/100],d_loss:0.151536,g_loss:6.772314 D real: 0.955839,D fake: 0.071023\n",
      "Epoch[1/100],d_loss:0.117181,g_loss:7.139060 D real: 0.968566,D fake: 0.066681\n",
      "Epoch[1/100],d_loss:0.392790,g_loss:6.311606 D real: 0.842735,D fake: 0.058087\n",
      "Epoch[2/100],d_loss:0.167021,g_loss:6.629264 D real: 0.937560,D fake: 0.052380\n",
      "Epoch[2/100],d_loss:0.419147,g_loss:5.027452 D real: 0.920970,D fake: 0.143419\n",
      "Epoch[2/100],d_loss:0.467001,g_loss:6.564289 D real: 0.829853,D fake: 0.053278\n",
      "Epoch[2/100],d_loss:0.312081,g_loss:8.657451 D real: 0.883533,D fake: 0.045477\n",
      "Epoch[3/100],d_loss:0.533541,g_loss:4.177750 D real: 0.890056,D fake: 0.163254\n",
      "Epoch[3/100],d_loss:1.531449,g_loss:3.495611 D real: 0.723230,D fake: 0.377799\n",
      "Epoch[3/100],d_loss:0.327840,g_loss:4.762254 D real: 0.851423,D fake: 0.042480\n",
      "Epoch[3/100],d_loss:0.239100,g_loss:5.126554 D real: 0.895416,D fake: 0.047541\n",
      "Epoch[4/100],d_loss:0.229083,g_loss:4.458138 D real: 0.935257,D fake: 0.106071\n",
      "Epoch[4/100],d_loss:0.164030,g_loss:6.303367 D real: 0.955009,D fake: 0.026825\n",
      "Epoch[4/100],d_loss:0.279324,g_loss:3.374020 D real: 0.955428,D fake: 0.143585\n",
      "Epoch[4/100],d_loss:0.087354,g_loss:4.423090 D real: 0.971381,D fake: 0.044887\n",
      "Epoch[5/100],d_loss:0.153829,g_loss:5.489940 D real: 0.964272,D fake: 0.067886\n",
      "Epoch[5/100],d_loss:0.095497,g_loss:5.007899 D real: 0.993708,D fake: 0.066648\n",
      "Epoch[5/100],d_loss:0.122635,g_loss:5.262297 D real: 0.957962,D fake: 0.030596\n",
      "Epoch[5/100],d_loss:0.044531,g_loss:6.846662 D real: 0.982567,D fake: 0.008173\n",
      "Epoch[6/100],d_loss:0.148989,g_loss:6.116880 D real: 0.932812,D fake: 0.016345\n",
      "Epoch[6/100],d_loss:0.119095,g_loss:6.548996 D real: 0.952046,D fake: 0.022620\n",
      "Epoch[6/100],d_loss:0.097915,g_loss:5.417562 D real: 0.973253,D fake: 0.050077\n",
      "Epoch[6/100],d_loss:0.117072,g_loss:4.807580 D real: 0.955403,D fake: 0.033371\n",
      "Epoch[7/100],d_loss:0.207770,g_loss:4.954582 D real: 0.993633,D fake: 0.158362\n",
      "Epoch[7/100],d_loss:0.121683,g_loss:2.903588 D real: 0.982628,D fake: 0.083772\n",
      "Epoch[7/100],d_loss:0.366458,g_loss:5.194783 D real: 0.945946,D fake: 0.149898\n",
      "Epoch[7/100],d_loss:0.186622,g_loss:5.181621 D real: 0.970916,D fake: 0.104396\n",
      "Epoch[8/100],d_loss:0.192584,g_loss:5.438768 D real: 0.950977,D fake: 0.061391\n",
      "Epoch[8/100],d_loss:0.174898,g_loss:4.402459 D real: 0.965389,D fake: 0.098913\n",
      "Epoch[8/100],d_loss:0.479659,g_loss:5.532819 D real: 0.821427,D fake: 0.036963\n",
      "Epoch[8/100],d_loss:0.605328,g_loss:4.564087 D real: 0.877982,D fake: 0.161844\n",
      "Epoch[9/100],d_loss:0.219267,g_loss:3.607026 D real: 0.983061,D fake: 0.146613\n",
      "Epoch[9/100],d_loss:0.235431,g_loss:4.898735 D real: 0.916469,D fake: 0.050378\n",
      "Epoch[9/100],d_loss:0.362463,g_loss:3.130211 D real: 0.914968,D fake: 0.157000\n",
      "Epoch[9/100],d_loss:0.279815,g_loss:3.784023 D real: 0.902871,D fake: 0.062675\n",
      "Epoch[10/100],d_loss:0.248804,g_loss:3.880919 D real: 0.953844,D fake: 0.119376\n",
      "Epoch[10/100],d_loss:0.398717,g_loss:4.775534 D real: 0.861553,D fake: 0.051179\n",
      "Epoch[10/100],d_loss:0.233729,g_loss:3.617292 D real: 0.955733,D fake: 0.084423\n",
      "Epoch[10/100],d_loss:0.280905,g_loss:4.443933 D real: 0.931833,D fake: 0.121664\n",
      "Epoch[11/100],d_loss:0.212278,g_loss:4.090020 D real: 0.920414,D fake: 0.076878\n",
      "Epoch[11/100],d_loss:0.359553,g_loss:4.760800 D real: 0.887794,D fake: 0.090316\n",
      "Epoch[11/100],d_loss:0.518752,g_loss:3.698639 D real: 0.856746,D fake: 0.125282\n",
      "Epoch[11/100],d_loss:0.164425,g_loss:4.328550 D real: 0.952746,D fake: 0.037138\n",
      "Epoch[12/100],d_loss:0.390853,g_loss:5.398691 D real: 0.897504,D fake: 0.058196\n",
      "Epoch[12/100],d_loss:0.443123,g_loss:4.491077 D real: 0.928965,D fake: 0.175575\n",
      "Epoch[12/100],d_loss:0.126386,g_loss:6.200356 D real: 0.931232,D fake: 0.024602\n",
      "Epoch[12/100],d_loss:0.166187,g_loss:3.933656 D real: 0.960134,D fake: 0.068030\n",
      "Epoch[13/100],d_loss:0.336000,g_loss:3.734963 D real: 0.882200,D fake: 0.074824\n",
      "Epoch[13/100],d_loss:0.345554,g_loss:4.961036 D real: 0.934368,D fake: 0.178802\n",
      "Epoch[13/100],d_loss:0.514637,g_loss:4.368699 D real: 0.907437,D fake: 0.148795\n",
      "Epoch[13/100],d_loss:0.214185,g_loss:4.773790 D real: 0.955018,D fake: 0.108634\n",
      "Epoch[14/100],d_loss:0.413672,g_loss:2.943522 D real: 0.909076,D fake: 0.123955\n",
      "Epoch[14/100],d_loss:0.531638,g_loss:3.886163 D real: 0.829558,D fake: 0.102353\n",
      "Epoch[14/100],d_loss:0.312723,g_loss:3.781184 D real: 0.924120,D fake: 0.133182\n",
      "Epoch[14/100],d_loss:0.237692,g_loss:4.699187 D real: 0.892882,D fake: 0.027217\n",
      "Epoch[15/100],d_loss:0.216415,g_loss:4.600679 D real: 0.940197,D fake: 0.085424\n",
      "Epoch[15/100],d_loss:0.255695,g_loss:3.715425 D real: 0.946739,D fake: 0.125571\n",
      "Epoch[15/100],d_loss:0.366639,g_loss:3.650935 D real: 0.910772,D fake: 0.097603\n",
      "Epoch[15/100],d_loss:0.397592,g_loss:3.832396 D real: 0.881579,D fake: 0.078235\n",
      "Epoch[16/100],d_loss:0.544557,g_loss:4.214627 D real: 0.833257,D fake: 0.147973\n",
      "Epoch[16/100],d_loss:0.243973,g_loss:3.863513 D real: 0.921644,D fake: 0.089955\n",
      "Epoch[16/100],d_loss:0.370633,g_loss:4.441736 D real: 0.952693,D fake: 0.212529\n",
      "Epoch[16/100],d_loss:0.385733,g_loss:3.965677 D real: 0.960359,D fake: 0.212782\n",
      "Epoch[17/100],d_loss:0.215017,g_loss:4.233489 D real: 0.920072,D fake: 0.040915\n",
      "Epoch[17/100],d_loss:0.580899,g_loss:2.953969 D real: 0.841765,D fake: 0.176212\n",
      "Epoch[17/100],d_loss:0.272154,g_loss:3.496354 D real: 0.950664,D fake: 0.154578\n",
      "Epoch[17/100],d_loss:0.320593,g_loss:4.179489 D real: 0.886753,D fake: 0.080049\n",
      "Epoch[18/100],d_loss:0.363306,g_loss:2.513564 D real: 0.935762,D fake: 0.182657\n",
      "Epoch[18/100],d_loss:0.219090,g_loss:4.149893 D real: 0.944161,D fake: 0.111767\n",
      "Epoch[18/100],d_loss:0.313972,g_loss:3.919600 D real: 0.874823,D fake: 0.082801\n",
      "Epoch[18/100],d_loss:0.242038,g_loss:3.392568 D real: 0.956394,D fake: 0.117492\n",
      "Epoch[19/100],d_loss:0.457744,g_loss:4.647859 D real: 0.841020,D fake: 0.111189\n",
      "Epoch[19/100],d_loss:0.355092,g_loss:5.133159 D real: 0.879078,D fake: 0.098876\n",
      "Epoch[19/100],d_loss:0.245469,g_loss:4.312779 D real: 0.943572,D fake: 0.101805\n",
      "Epoch[19/100],d_loss:0.420701,g_loss:4.791534 D real: 0.865857,D fake: 0.117300\n",
      "Epoch[20/100],d_loss:0.377484,g_loss:5.032549 D real: 0.898423,D fake: 0.127103\n",
      "Epoch[20/100],d_loss:0.307647,g_loss:4.195929 D real: 0.909679,D fake: 0.108729\n",
      "Epoch[20/100],d_loss:0.230781,g_loss:4.872607 D real: 0.898760,D fake: 0.037257\n",
      "Epoch[20/100],d_loss:0.315869,g_loss:5.611705 D real: 0.913832,D fake: 0.103718\n",
      "Epoch[21/100],d_loss:0.295100,g_loss:3.773246 D real: 0.950795,D fake: 0.143247\n",
      "Epoch[21/100],d_loss:0.254906,g_loss:5.895406 D real: 0.936724,D fake: 0.054404\n",
      "Epoch[21/100],d_loss:0.232510,g_loss:4.208651 D real: 0.899978,D fake: 0.053025\n",
      "Epoch[21/100],d_loss:0.578911,g_loss:3.149797 D real: 0.797119,D fake: 0.126504\n",
      "Epoch[22/100],d_loss:0.306697,g_loss:3.005612 D real: 0.934202,D fake: 0.143486\n",
      "Epoch[22/100],d_loss:0.636528,g_loss:3.151639 D real: 0.877376,D fake: 0.230221\n",
      "Epoch[22/100],d_loss:0.362737,g_loss:2.981183 D real: 0.866347,D fake: 0.082143\n",
      "Epoch[22/100],d_loss:0.439933,g_loss:4.023624 D real: 0.859397,D fake: 0.114101\n",
      "Epoch[23/100],d_loss:0.385545,g_loss:4.026974 D real: 0.883659,D fake: 0.076454\n",
      "Epoch[23/100],d_loss:0.369033,g_loss:3.613798 D real: 0.921515,D fake: 0.184835\n",
      "Epoch[23/100],d_loss:0.527107,g_loss:2.538057 D real: 0.889974,D fake: 0.210045\n",
      "Epoch[23/100],d_loss:0.469734,g_loss:3.477174 D real: 0.887971,D fake: 0.154685\n",
      "Epoch[24/100],d_loss:0.582482,g_loss:3.565820 D real: 0.836873,D fake: 0.114670\n",
      "Epoch[24/100],d_loss:0.314350,g_loss:3.323647 D real: 0.887227,D fake: 0.089163\n",
      "Epoch[24/100],d_loss:0.317742,g_loss:3.661797 D real: 0.874133,D fake: 0.054432\n",
      "Epoch[24/100],d_loss:0.223495,g_loss:4.372494 D real: 0.929142,D fake: 0.090313\n",
      "Epoch[25/100],d_loss:0.741539,g_loss:3.179328 D real: 0.794795,D fake: 0.178004\n",
      "Epoch[25/100],d_loss:0.206190,g_loss:5.438038 D real: 0.936242,D fake: 0.049857\n",
      "Epoch[25/100],d_loss:0.299256,g_loss:4.312375 D real: 0.937107,D fake: 0.124940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[25/100],d_loss:0.403014,g_loss:3.332253 D real: 0.876668,D fake: 0.120749\n",
      "Epoch[26/100],d_loss:0.366813,g_loss:3.813542 D real: 0.860976,D fake: 0.056349\n",
      "Epoch[26/100],d_loss:0.461906,g_loss:2.997100 D real: 0.822825,D fake: 0.084134\n",
      "Epoch[26/100],d_loss:0.274860,g_loss:3.522914 D real: 0.936404,D fake: 0.127159\n",
      "Epoch[26/100],d_loss:0.305017,g_loss:4.137588 D real: 0.923163,D fake: 0.123772\n",
      "Epoch[27/100],d_loss:0.229643,g_loss:2.798690 D real: 0.942511,D fake: 0.109280\n",
      "Epoch[27/100],d_loss:0.402342,g_loss:4.013432 D real: 0.894545,D fake: 0.169040\n",
      "Epoch[27/100],d_loss:0.630799,g_loss:4.158404 D real: 0.907590,D fake: 0.273873\n",
      "Epoch[27/100],d_loss:0.319488,g_loss:3.685061 D real: 0.934034,D fake: 0.143561\n",
      "Epoch[28/100],d_loss:0.363905,g_loss:4.429831 D real: 0.944067,D fake: 0.148555\n",
      "Epoch[28/100],d_loss:0.505388,g_loss:3.296499 D real: 0.845062,D fake: 0.155388\n",
      "Epoch[28/100],d_loss:0.396648,g_loss:2.858813 D real: 0.879402,D fake: 0.094392\n",
      "Epoch[28/100],d_loss:0.309831,g_loss:4.544317 D real: 0.896012,D fake: 0.089018\n",
      "Epoch[29/100],d_loss:0.559506,g_loss:3.021845 D real: 0.832169,D fake: 0.134983\n",
      "Epoch[29/100],d_loss:0.611186,g_loss:2.552802 D real: 0.853094,D fake: 0.210826\n",
      "Epoch[29/100],d_loss:0.425520,g_loss:3.645673 D real: 0.895687,D fake: 0.164555\n",
      "Epoch[29/100],d_loss:0.377929,g_loss:3.741921 D real: 0.848470,D fake: 0.059616\n",
      "Epoch[30/100],d_loss:0.469137,g_loss:2.814606 D real: 0.917093,D fake: 0.223833\n",
      "Epoch[30/100],d_loss:0.396036,g_loss:4.437236 D real: 0.863513,D fake: 0.104466\n",
      "Epoch[30/100],d_loss:0.215099,g_loss:4.429688 D real: 0.935644,D fake: 0.080259\n",
      "Epoch[30/100],d_loss:0.431618,g_loss:2.686641 D real: 0.894568,D fake: 0.195095\n",
      "Epoch[31/100],d_loss:0.384663,g_loss:2.535137 D real: 0.878816,D fake: 0.143811\n",
      "Epoch[31/100],d_loss:0.510720,g_loss:3.501195 D real: 0.896459,D fake: 0.193010\n",
      "Epoch[31/100],d_loss:0.503283,g_loss:4.014537 D real: 0.893997,D fake: 0.177332\n",
      "Epoch[31/100],d_loss:0.313404,g_loss:3.722521 D real: 0.931045,D fake: 0.135839\n",
      "Epoch[32/100],d_loss:0.665132,g_loss:2.240238 D real: 0.841348,D fake: 0.205854\n",
      "Epoch[32/100],d_loss:0.313527,g_loss:3.274352 D real: 0.890929,D fake: 0.115158\n",
      "Epoch[32/100],d_loss:0.506173,g_loss:3.282120 D real: 0.783364,D fake: 0.051395\n",
      "Epoch[32/100],d_loss:0.563926,g_loss:3.532317 D real: 0.850341,D fake: 0.153467\n",
      "Epoch[33/100],d_loss:0.474263,g_loss:3.145582 D real: 0.857386,D fake: 0.133909\n",
      "Epoch[33/100],d_loss:0.544272,g_loss:3.549083 D real: 0.820258,D fake: 0.106612\n",
      "Epoch[33/100],d_loss:0.581275,g_loss:3.394417 D real: 0.788117,D fake: 0.108483\n",
      "Epoch[33/100],d_loss:0.472202,g_loss:2.846359 D real: 0.883194,D fake: 0.204881\n",
      "Epoch[34/100],d_loss:0.638825,g_loss:3.808478 D real: 0.770765,D fake: 0.123037\n",
      "Epoch[34/100],d_loss:0.597244,g_loss:3.085907 D real: 0.912359,D fake: 0.255101\n",
      "Epoch[34/100],d_loss:0.478038,g_loss:3.506615 D real: 0.866793,D fake: 0.159615\n",
      "Epoch[34/100],d_loss:0.546112,g_loss:2.792170 D real: 0.889271,D fake: 0.219397\n",
      "Epoch[35/100],d_loss:0.460243,g_loss:3.429475 D real: 0.900447,D fake: 0.200281\n",
      "Epoch[35/100],d_loss:0.449928,g_loss:3.922853 D real: 0.847572,D fake: 0.078095\n",
      "Epoch[35/100],d_loss:0.355919,g_loss:2.599414 D real: 0.926098,D fake: 0.182956\n",
      "Epoch[35/100],d_loss:0.579171,g_loss:3.185236 D real: 0.805201,D fake: 0.085245\n",
      "Epoch[36/100],d_loss:0.499182,g_loss:3.994914 D real: 0.780836,D fake: 0.070987\n",
      "Epoch[36/100],d_loss:0.245562,g_loss:4.220542 D real: 0.953563,D fake: 0.139809\n",
      "Epoch[36/100],d_loss:0.387998,g_loss:4.146057 D real: 0.940676,D fake: 0.197504\n",
      "Epoch[36/100],d_loss:0.387759,g_loss:3.635362 D real: 0.866147,D fake: 0.113626\n",
      "Epoch[37/100],d_loss:0.432021,g_loss:2.999715 D real: 0.876580,D fake: 0.126674\n",
      "Epoch[37/100],d_loss:0.561627,g_loss:3.458685 D real: 0.789591,D fake: 0.105067\n",
      "Epoch[37/100],d_loss:0.469795,g_loss:3.055098 D real: 0.868365,D fake: 0.125809\n",
      "Epoch[37/100],d_loss:0.436543,g_loss:3.471462 D real: 0.901063,D fake: 0.183335\n",
      "Epoch[38/100],d_loss:0.415252,g_loss:3.755025 D real: 0.849348,D fake: 0.103629\n",
      "Epoch[38/100],d_loss:0.387888,g_loss:2.705962 D real: 0.821461,D fake: 0.064258\n",
      "Epoch[38/100],d_loss:0.505649,g_loss:4.093608 D real: 0.794622,D fake: 0.090998\n",
      "Epoch[38/100],d_loss:0.388646,g_loss:3.144401 D real: 0.863836,D fake: 0.096137\n",
      "Epoch[39/100],d_loss:0.471149,g_loss:2.396815 D real: 0.846154,D fake: 0.140899\n",
      "Epoch[39/100],d_loss:0.510077,g_loss:2.876092 D real: 0.922118,D fake: 0.244772\n",
      "Epoch[39/100],d_loss:0.578166,g_loss:3.061382 D real: 0.865750,D fake: 0.225893\n",
      "Epoch[39/100],d_loss:0.515179,g_loss:2.220522 D real: 0.861201,D fake: 0.190869\n",
      "Epoch[40/100],d_loss:0.421302,g_loss:3.252340 D real: 0.819300,D fake: 0.059033\n",
      "Epoch[40/100],d_loss:0.418907,g_loss:3.055099 D real: 0.883430,D fake: 0.148410\n",
      "Epoch[40/100],d_loss:0.550861,g_loss:2.939883 D real: 0.786207,D fake: 0.098120\n",
      "Epoch[40/100],d_loss:0.556259,g_loss:2.990352 D real: 0.918614,D fake: 0.259856\n",
      "Epoch[41/100],d_loss:0.687254,g_loss:2.828022 D real: 0.741373,D fake: 0.070991\n",
      "Epoch[41/100],d_loss:0.457203,g_loss:3.977676 D real: 0.836728,D fake: 0.096804\n",
      "Epoch[41/100],d_loss:0.420041,g_loss:3.252840 D real: 0.850283,D fake: 0.095277\n",
      "Epoch[41/100],d_loss:0.392215,g_loss:3.377010 D real: 0.839927,D fake: 0.096797\n",
      "Epoch[42/100],d_loss:0.586211,g_loss:2.782050 D real: 0.795366,D fake: 0.106776\n",
      "Epoch[42/100],d_loss:0.312563,g_loss:2.843722 D real: 0.928342,D fake: 0.163633\n",
      "Epoch[42/100],d_loss:0.723498,g_loss:2.802180 D real: 0.854416,D fake: 0.278773\n",
      "Epoch[42/100],d_loss:0.725706,g_loss:3.501141 D real: 0.825029,D fake: 0.216710\n",
      "Epoch[43/100],d_loss:0.351868,g_loss:3.120203 D real: 0.895876,D fake: 0.147827\n",
      "Epoch[43/100],d_loss:0.568232,g_loss:2.371502 D real: 0.864486,D fake: 0.195115\n",
      "Epoch[43/100],d_loss:0.470598,g_loss:2.968492 D real: 0.886201,D fake: 0.183133\n",
      "Epoch[43/100],d_loss:0.386059,g_loss:2.932038 D real: 0.899970,D fake: 0.171910\n",
      "Epoch[44/100],d_loss:0.441865,g_loss:3.161877 D real: 0.841490,D fake: 0.144357\n",
      "Epoch[44/100],d_loss:0.776021,g_loss:2.389427 D real: 0.806798,D fake: 0.228597\n",
      "Epoch[44/100],d_loss:0.371677,g_loss:4.322245 D real: 0.853165,D fake: 0.084959\n",
      "Epoch[44/100],d_loss:0.540472,g_loss:3.535953 D real: 0.805749,D fake: 0.108353\n",
      "Epoch[45/100],d_loss:0.642520,g_loss:2.054853 D real: 0.837468,D fake: 0.147552\n",
      "Epoch[45/100],d_loss:0.604718,g_loss:2.529083 D real: 0.942120,D fake: 0.288695\n",
      "Epoch[45/100],d_loss:0.572906,g_loss:2.374175 D real: 0.875998,D fake: 0.235108\n",
      "Epoch[45/100],d_loss:0.594151,g_loss:2.485828 D real: 0.819100,D fake: 0.153524\n",
      "Epoch[46/100],d_loss:0.329110,g_loss:3.980104 D real: 0.864723,D fake: 0.094074\n",
      "Epoch[46/100],d_loss:0.414893,g_loss:2.999069 D real: 0.892335,D fake: 0.158028\n",
      "Epoch[46/100],d_loss:0.522256,g_loss:3.130840 D real: 0.882010,D fake: 0.198944\n",
      "Epoch[46/100],d_loss:0.589528,g_loss:2.888176 D real: 0.789149,D fake: 0.150448\n",
      "Epoch[47/100],d_loss:0.361634,g_loss:3.038726 D real: 0.877173,D fake: 0.132772\n",
      "Epoch[47/100],d_loss:0.431524,g_loss:3.697719 D real: 0.852569,D fake: 0.108313\n",
      "Epoch[47/100],d_loss:0.586220,g_loss:2.684875 D real: 0.848595,D fake: 0.195837\n",
      "Epoch[47/100],d_loss:0.572716,g_loss:2.692683 D real: 0.851527,D fake: 0.210092\n",
      "Epoch[48/100],d_loss:0.399747,g_loss:2.937519 D real: 0.867096,D fake: 0.142404\n",
      "Epoch[48/100],d_loss:0.925823,g_loss:3.366429 D real: 0.675406,D fake: 0.109925\n",
      "Epoch[48/100],d_loss:0.622220,g_loss:2.907394 D real: 0.770881,D fake: 0.123632\n",
      "Epoch[48/100],d_loss:0.632351,g_loss:2.326916 D real: 0.855010,D fake: 0.232746\n",
      "Epoch[49/100],d_loss:0.538020,g_loss:2.110125 D real: 0.817338,D fake: 0.159703\n",
      "Epoch[49/100],d_loss:0.784049,g_loss:2.165957 D real: 0.821837,D fake: 0.261806\n",
      "Epoch[49/100],d_loss:0.600172,g_loss:2.766028 D real: 0.765489,D fake: 0.122867\n",
      "Epoch[49/100],d_loss:0.475098,g_loss:2.781908 D real: 0.885875,D fake: 0.206956\n",
      "Epoch[50/100],d_loss:0.824970,g_loss:1.981063 D real: 0.796407,D fake: 0.275920\n",
      "Epoch[50/100],d_loss:0.620533,g_loss:2.717465 D real: 0.839221,D fake: 0.232851\n",
      "Epoch[50/100],d_loss:0.570289,g_loss:3.155636 D real: 0.798741,D fake: 0.119883\n",
      "Epoch[50/100],d_loss:0.538934,g_loss:2.672735 D real: 0.836114,D fake: 0.203886\n",
      "Epoch[51/100],d_loss:0.635836,g_loss:2.599678 D real: 0.871340,D fake: 0.262984\n",
      "Epoch[51/100],d_loss:0.579749,g_loss:2.909263 D real: 0.776228,D fake: 0.133344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[51/100],d_loss:0.576327,g_loss:2.507119 D real: 0.792220,D fake: 0.139435\n",
      "Epoch[51/100],d_loss:0.578047,g_loss:1.989577 D real: 0.831629,D fake: 0.212883\n",
      "Epoch[52/100],d_loss:0.631901,g_loss:2.355064 D real: 0.834017,D fake: 0.212209\n",
      "Epoch[52/100],d_loss:0.800376,g_loss:3.180791 D real: 0.769228,D fake: 0.202079\n",
      "Epoch[52/100],d_loss:0.476539,g_loss:3.085685 D real: 0.853949,D fake: 0.162837\n",
      "Epoch[52/100],d_loss:0.634169,g_loss:1.870641 D real: 0.790430,D fake: 0.187205\n",
      "Epoch[53/100],d_loss:0.496641,g_loss:2.804884 D real: 0.861311,D fake: 0.204600\n",
      "Epoch[53/100],d_loss:0.569249,g_loss:3.091474 D real: 0.831089,D fake: 0.174522\n",
      "Epoch[53/100],d_loss:0.678682,g_loss:2.744714 D real: 0.808703,D fake: 0.184675\n",
      "Epoch[53/100],d_loss:0.657804,g_loss:2.639785 D real: 0.785750,D fake: 0.175325\n",
      "Epoch[54/100],d_loss:0.538775,g_loss:3.043095 D real: 0.777312,D fake: 0.079287\n",
      "Epoch[54/100],d_loss:0.611907,g_loss:2.818621 D real: 0.827947,D fake: 0.190734\n",
      "Epoch[54/100],d_loss:0.385210,g_loss:3.191054 D real: 0.886695,D fake: 0.163904\n",
      "Epoch[54/100],d_loss:0.774179,g_loss:2.121918 D real: 0.756011,D fake: 0.236676\n",
      "Epoch[55/100],d_loss:0.462532,g_loss:2.576676 D real: 0.869323,D fake: 0.195985\n",
      "Epoch[55/100],d_loss:0.493611,g_loss:3.455633 D real: 0.869438,D fake: 0.177896\n",
      "Epoch[55/100],d_loss:0.572358,g_loss:3.655525 D real: 0.815848,D fake: 0.174744\n",
      "Epoch[55/100],d_loss:0.520437,g_loss:3.200763 D real: 0.834004,D fake: 0.156337\n",
      "Epoch[56/100],d_loss:0.691721,g_loss:2.397567 D real: 0.783394,D fake: 0.166280\n",
      "Epoch[56/100],d_loss:0.545162,g_loss:3.048826 D real: 0.763969,D fake: 0.084158\n",
      "Epoch[56/100],d_loss:0.655712,g_loss:2.840896 D real: 0.800206,D fake: 0.206222\n",
      "Epoch[56/100],d_loss:0.666889,g_loss:2.710039 D real: 0.748524,D fake: 0.144275\n",
      "Epoch[57/100],d_loss:0.466396,g_loss:2.410328 D real: 0.834935,D fake: 0.180181\n",
      "Epoch[57/100],d_loss:0.617894,g_loss:2.424574 D real: 0.871934,D fake: 0.233148\n",
      "Epoch[57/100],d_loss:0.634485,g_loss:2.610038 D real: 0.776449,D fake: 0.159879\n",
      "Epoch[57/100],d_loss:0.767329,g_loss:3.424629 D real: 0.810642,D fake: 0.237980\n",
      "Epoch[58/100],d_loss:0.749231,g_loss:2.211096 D real: 0.750756,D fake: 0.197165\n",
      "Epoch[58/100],d_loss:0.548632,g_loss:2.666434 D real: 0.811977,D fake: 0.129596\n",
      "Epoch[58/100],d_loss:0.515314,g_loss:2.395057 D real: 0.841382,D fake: 0.171363\n",
      "Epoch[58/100],d_loss:0.746571,g_loss:2.202648 D real: 0.828012,D fake: 0.289265\n",
      "Epoch[59/100],d_loss:0.705641,g_loss:2.365350 D real: 0.735941,D fake: 0.169070\n",
      "Epoch[59/100],d_loss:0.468982,g_loss:2.963998 D real: 0.838288,D fake: 0.148261\n",
      "Epoch[59/100],d_loss:0.590017,g_loss:2.290915 D real: 0.776300,D fake: 0.152513\n",
      "Epoch[59/100],d_loss:0.527122,g_loss:2.112945 D real: 0.785387,D fake: 0.144937\n",
      "Epoch[60/100],d_loss:0.676059,g_loss:2.195834 D real: 0.795590,D fake: 0.229261\n",
      "Epoch[60/100],d_loss:0.667823,g_loss:2.227451 D real: 0.826123,D fake: 0.227398\n",
      "Epoch[60/100],d_loss:0.592594,g_loss:2.173796 D real: 0.799469,D fake: 0.191003\n",
      "Epoch[60/100],d_loss:0.644216,g_loss:1.900825 D real: 0.876793,D fake: 0.305631\n",
      "Epoch[61/100],d_loss:0.634912,g_loss:2.284767 D real: 0.755331,D fake: 0.142592\n",
      "Epoch[61/100],d_loss:0.663110,g_loss:1.632352 D real: 0.768253,D fake: 0.187869\n",
      "Epoch[61/100],d_loss:0.660986,g_loss:2.154809 D real: 0.809793,D fake: 0.221150\n",
      "Epoch[61/100],d_loss:0.706514,g_loss:2.809359 D real: 0.718296,D fake: 0.145831\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: UTF-8 -*-\n",
    " \n",
    "# coding=utf-8\n",
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    " \n",
    "# 创建文件夹\n",
    "if not os.path.exists('./img'):\n",
    "    os.mkdir('./img')\n",
    " \n",
    " \n",
    "def to_img(x):\n",
    "    out = 0.5 * (x + 1)\n",
    "    out = out.clamp(0, 1)  # Clamp函数可以将随机变化的数值限制在一个给定的区间[min, max]内：\n",
    "    out = out.view(-1, 1, 28, 28)  # view()函数作用是将一个多行的Tensor,拼接成一行，把向量变成矩阵的形式\n",
    "    return out\n",
    " \n",
    " \n",
    "batch_size = 128\n",
    "num_epoch = 100\n",
    "z_dimension = 100\n",
    "# 图像预处理\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # (x-mean) / std\n",
    "])\n",
    " \n",
    "# mnist dataset mnist数据集下载\n",
    "mnist = datasets.MNIST(\n",
    "    root='./data/', train=True, transform=img_transform, download=True \n",
    ") #训练集\n",
    " \n",
    "# data loader 数据载入\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=mnist, batch_size=batch_size, shuffle=True\n",
    ")\n",
    " \n",
    " \n",
    "# 定义判别器  #####Discriminator######使用多层网络来作为判别器\n",
    "# 将图片28x28展开成784，然后通过多层感知器，中间经过斜率设置为0.2的LeakyReLU激活函数，\n",
    "# 最后接sigmoid激活函数得到一个0到1之间的概率进行二分类。\n",
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.dis = nn.Sequential(\n",
    "            nn.Linear(784, 256),  # 输入特征数为784，输出为256\n",
    "            nn.LeakyReLU(0.2),  # 进行非线性映射\n",
    "            nn.Linear(256, 256),  # 进行一个线性映射\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()  # 也是一个激活函数，二分类问题中，\n",
    "            # sigmoid可以班实数映射到【0,1】，作为概率值，\n",
    "            # 多分类用softmax函数\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.dis(x)\n",
    "        return x\n",
    " \n",
    " \n",
    "# ###### 定义生成器 Generator ##### x = G(z, θg)，输入一个随机的分布z，输出一个x（x属于Pg分布）\n",
    "# 输入一个100维的0～1之间的高斯分布，然后通过第一层线性变换将其映射到256维,\n",
    "# 然后通过ReLU激活函数，接着进行一个线性变换，再经过一个ReLU激活函数，\n",
    "# 然后经过线性变换将其变成784维，最后经过Tanh激活函数是希望生成的假的图片数据分布\n",
    "# 能够在-1～1之间。\n",
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(100, 256),  # 用线性变换将输入映射到256维\n",
    "            nn.ReLU(True),  # relu激活\n",
    "            nn.Linear(256, 256),  # 线性变换\n",
    "            nn.ReLU(True),  # relu激活\n",
    "            nn.Linear(256, 784),  # 线性变换\n",
    "            nn.Tanh()  # Tanh激活使得生成数据分布在【-1,1】之间，因为输入的真实数据的经过transforms之后也是这个分布\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.gen(x)\n",
    "        return x\n",
    " \n",
    " \n",
    "# 创建对象\n",
    "D = discriminator()\n",
    "G = generator()\n",
    "if torch.cuda.is_available():\n",
    "    D = D.cuda()\n",
    "    G = G.cuda()\n",
    " \n",
    "# 首先需要定义loss的度量方式  （二分类的交叉熵）\n",
    "# 其次定义 优化函数,优化函数的学习率为0.0003\n",
    "criterion = nn.BCELoss()  # 是单目标二分类交叉熵函数\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0003)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0003)\n",
    " \n",
    "# ##########################进入训练##判别器的判断过程#####################\n",
    "for epoch in range(num_epoch):  # 进行多个epoch的训练\n",
    "    for i, (img, _) in enumerate(dataloader):\n",
    "        num_img = img.size(0)\n",
    "        # view()函数作用是将一个多行的Tensor,拼接成一行\n",
    "        # 第一个参数是要拼接的tensor,第二个参数是-1\n",
    "        # =============================训练判别器==================\n",
    "        img = img.view(num_img, -1)  # 将图片展开为28*28=784\n",
    "        real_img = Variable(img).cuda()  # 将tensor变成Variable放入计算图中\n",
    "        real_label = Variable(torch.ones(num_img)).cuda()  # 定义真实的图片label为1\n",
    "        fake_label = Variable(torch.zeros(num_img)).cuda()  # 定义假的图片的label为0\n",
    " \n",
    "        # ########判别器训练train#####################\n",
    "        # 分为两部分：1、真的图像判别为真；2、假的图像判别为假\n",
    "        # 计算真实图片的损失\n",
    "        real_out = D(real_img)  # 将真实图片放入判别器中\n",
    "        real_out = real_out.squeeze()  # (128,1) -> (128,)\n",
    "        d_loss_real = criterion(real_out, real_label)  # 得到真实图片的loss\n",
    "        real_scores = real_out  # 得到真实图片的判别值，输出的值越接近1越好\n",
    "        # 计算假的图片的损失\n",
    "        z = Variable(torch.randn(num_img, z_dimension)).cuda()  # 随机生成一些噪声\n",
    "        fake_img = G(z).detach()  # 随机噪声放入生成网络中，生成一张假的图片。 # 避免梯度传到G，因为G不用更新, detach分离\n",
    "        fake_out = D(fake_img)  # 判别器判断假的图片，\n",
    "        fake_out = fake_out.squeeze()  # (128,1) -> (128,)\n",
    "        d_loss_fake = criterion(fake_out, fake_label)  # 得到假的图片的loss\n",
    "        fake_scores = fake_out  # 得到假图片的判别值，对于判别器来说，假图片的损失越接近0越好\n",
    "        # 损失函数和优化\n",
    "        d_loss = d_loss_real + d_loss_fake  # 损失包括判真损失和判假损失\n",
    "        d_optimizer.zero_grad()  # 在反向传播之前，先将梯度归0\n",
    "        d_loss.backward()  # 将误差反向传播\n",
    "        d_optimizer.step()  # 更新参数\n",
    " \n",
    "        # ==================训练生成器============================\n",
    "        # ###############################生成网络的训练###############################\n",
    "        # 原理：目的是希望生成的假的图片被判别器判断为真的图片，\n",
    "        # 在此过程中，将判别器固定，将假的图片传入判别器的结果与真实的label对应，\n",
    "        # 反向传播更新的参数是生成网络里面的参数，\n",
    "        # 这样可以通过更新生成网络里面的参数，来训练网络，使得生成的图片让判别器以为是真的\n",
    "        # 这样就达到了对抗的目的\n",
    "        # 计算假的图片的损失\n",
    "        z = Variable(torch.randn(num_img, z_dimension)).cuda()  # 得到随机噪声\n",
    "        fake_img = G(z)  # 随机噪声输入到生成器中，得到一副假的图片\n",
    "        output = D(fake_img)  # 经过判别器得到的结果\n",
    "        output = output.squeeze()\n",
    "        g_loss = criterion(output, real_label)  # 得到的假的图片与真实的图片的label的loss\n",
    "        # bp and optimize\n",
    "        g_optimizer.zero_grad()  # 梯度归0\n",
    "        g_loss.backward()  # 进行反向传播\n",
    "        g_optimizer.step()  # .step()一般用在反向传播后面,用于更新生成网络的参数\n",
    " \n",
    "        # 打印中间的损失\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch[{}/{}],d_loss:{:.6f},g_loss:{:.6f} '\n",
    "                  'D real: {:.6f},D fake: {:.6f}'.format(\n",
    "                epoch, num_epoch, d_loss.data.item(), g_loss.data.item(),\n",
    "                real_scores.data.mean(), fake_scores.data.mean()  # 打印的是真实图片的损失均值\n",
    "            )) #理论上当real_scores.data.mean()和fake_scores.data.mean()都为0.5时是训练效果最好的时候\n",
    "        if epoch == 0 and i == len(dataloader)-1: # 记录一下真实的数据（最后一个batch）\n",
    "            real_images = to_img(real_img.cpu().data)\n",
    "            save_image(real_images, './img/real_images.png')\n",
    "    if i == len(dataloader)-1:\n",
    "        fake_images = to_img(fake_img.cpu().data)\n",
    "        save_image(fake_images, './img/fake_images-{}.png'.format(epoch + 1))\n",
    " \n",
    "# 保存模型\n",
    "torch.save(G.state_dict(), './generator.pth')\n",
    "torch.save(D.state_dict(), './discriminator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24188c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "pytorch_visdom",
   "language": "python",
   "name": "pytorch_visdom3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
