{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7730510",
   "metadata": {},
   "source": [
    "Pytorch复现ResNet，对minist数据集进行分类  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7d9fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d376f7",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a378534",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "transform = transforms.Compose([\n",
    "   transforms.ToTensor(), #ToTensor()能够把灰度范围从0-255变换到0-1之间\n",
    "   transforms.Normalize((0.1307,),(0.3081,)) #transform.Normalize()则把0-1变换到(-1,1)，只有一个通道所以有1个值，第一位是均值，第二位是标准差\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root = '../dataset/mnist',\n",
    "                              train = True,\n",
    "                              download = True,\n",
    "                              transform = transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_dataset = datasets.MNIST(root = '../dataset/mnist',\n",
    "                             train = False,\n",
    "                             download = True,\n",
    "                             transform = transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2d959f",
   "metadata": {},
   "source": [
    "# Design Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc925798",
   "metadata": {},
   "source": [
    "<img src=\"https://markdown-yqguo.oss-cn-beijing.aliyuncs.com/markdown-yqguo/image-20220210122517037.png\" alt=\"image-20220210122517037\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d1e026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,channels):\n",
    "        super(ResidualBlock,self).__init__()\n",
    "        self.channels=channels\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(channels,channels,kernel_size=3,padding=1)\n",
    "    def forward(self,x):\n",
    "        y=F.relu(self.conv1(x))\n",
    "        y=self.conv2(y)\n",
    "        return F.relu(y+x) #与x相加后再激活"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a731ad",
   "metadata": {},
   "source": [
    "<img src=\"https://markdown-yqguo.oss-cn-beijing.aliyuncs.com/markdown-yqguo/image-20220210135808693.png\" alt=\"image-20220210135808693\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94708331",
   "metadata": {},
   "source": [
    "## 其他结构的Resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f68f11",
   "metadata": {},
   "source": [
    "参考文献：https://arxiv.org/pdf/1603.05027.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc407f",
   "metadata": {},
   "source": [
    "### constant scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189f9942",
   "metadata": {},
   "source": [
    "<img src=\"https://markdown-yqguo.oss-cn-beijing.aliyuncs.com/markdown-yqguo/image-20220210190421669.png\" alt=\"image-20220210190421669\" style=\"zoom: 50%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f1ad9d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock_b(nn.Module):\n",
    "    def __init__(self,channels):\n",
    "        super(ResidualBlock_b,self).__init__()\n",
    "        self.channels=channels\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(channels,channels,kernel_size=3,padding=1)\n",
    "    def forward(self,x):\n",
    "        y=F.relu(self.conv1(x))\n",
    "        y=self.conv2(y)\n",
    "        return F.relu(0.5*y+0.5*x) #与x相加后再激活"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a3e42",
   "metadata": {},
   "source": [
    "### exclusive gating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149d72b0",
   "metadata": {},
   "source": [
    "<img src=\"https://markdown-yqguo.oss-cn-beijing.aliyuncs.com/markdown-yqguo/image-20220210193303728.png\" alt=\"image-20220210193303728\" style=\"zoom: 50%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ed077c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock_c(nn.Module):\n",
    "    def __init__(self,channels):\n",
    "        super(ResidualBlock_c,self).__init__()\n",
    "        self.channels=channels\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(channels,channels,kernel_size=3,padding=1)\n",
    "        \n",
    "        sekf.conv1x1 = nn.Conv2d(channels,channels,kernel=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y=F.relu(self.conv1(x))\n",
    "        y=self.conv2(y)\n",
    "        \n",
    "        conv1x1 = F.sigmoid(self.conv1x1(x))\n",
    "        \n",
    "        x = x*(1-conv1x1)\n",
    "        \n",
    "        y = y*conv1x1\n",
    "        \n",
    "        return F.relu(y+x) #与x相加后再激活"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b31f7d",
   "metadata": {},
   "source": [
    "###  shortcut-only gating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2772803b",
   "metadata": {},
   "source": [
    "<img src=\"https://markdown-yqguo.oss-cn-beijing.aliyuncs.com/markdown-yqguo/image-20220210194239715.png\" alt=\"image-20220210194239715\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66c68197",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock_d(nn.Module):\n",
    "    def __init__(self_d,channels):\n",
    "        super(ResidualBlock,self).__init__()\n",
    "        self.channels=channels\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(channels,channels,kernel_size=3,padding=1)\n",
    "        \n",
    "        sekf.conv1x1 = nn.Conv2d(channels,channels,kernel=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y=F.relu(self.conv1(x))\n",
    "        y=self.conv2(y)\n",
    "        \n",
    "        conv1x1 = F.sigmoid(self.conv1x1(x))\n",
    "        \n",
    "        x = x*(1-conv1x1)\n",
    "        \n",
    "        return F.relu(y+x) #与x相加后再激活"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f53e1",
   "metadata": {},
   "source": [
    "### conv shortcut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876b7b3b",
   "metadata": {},
   "source": [
    "<img src=\"https://markdown-yqguo.oss-cn-beijing.aliyuncs.com/markdown-yqguo/image-20220210194409750.png\" alt=\"image-20220210194409750\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fb000823",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock_e(nn.Module):\n",
    "    def __init__(self,channels):\n",
    "        super(ResidualBlock_e,self).__init__()\n",
    "        self.channels=channels\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(channels,channels,kernel_size=3,padding=1)\n",
    "        \n",
    "        sekf.conv1x1 = nn.Conv2d(channels,channels,kernel=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y=F.relu(self.conv1(x))\n",
    "        y=self.conv2(y)\n",
    "        \n",
    "        x = self.conv1x1(x)\n",
    "        \n",
    "        return F.relu(y+x) #与x相加后再激活"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bda334",
   "metadata": {},
   "source": [
    "### dropout shortcut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19669a51",
   "metadata": {},
   "source": [
    "<img src=\"https://markdown-yqguo.oss-cn-beijing.aliyuncs.com/markdown-yqguo/image-20220210194628363.png\" alt=\"image-20220210194628363\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "94cf4b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock_f(nn.Module):\n",
    "    def __init__(self,channels):\n",
    "        super(ResidualBlock_f,self).__init__()\n",
    "        self.channels=channels\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(channels,channels,kernel_size=3,padding=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y=F.relu(self.conv1(x))\n",
    "        y=self.conv2(y)\n",
    "        \n",
    "        x = F.dropout(x,p=0.5)\n",
    "        \n",
    "        return F.relu(y+x) #与x相加后再激活"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a66fb",
   "metadata": {},
   "source": [
    "### 放到网络中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b0f7e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,16,kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(16,32,kernel_size=5)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.rblock1 = ResidualBlock_f(16)\n",
    "        self.rblock2 = ResidualBlock_f(32)\n",
    "        \n",
    "        self.fc = nn.Linear(512,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        in_size = x.size(0)\n",
    "        x=self.mp(F.relu(self.conv1(x)))\n",
    "        x=self.rblock1(x)\n",
    "        x=self.mp(F.relu(self.conv2(x)))\n",
    "        x=self.rblock2(x)\n",
    "        x=x.view(in_size,-1)\n",
    "        #print(x.size())\n",
    "        x=self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2e91d1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化一个输入x，算一下全连接层的输入是几维的\n",
    "x = torch.rand([1,1,28,28])\n",
    "net = Net()\n",
    "with torch.no_grad():\n",
    "    net(x) #torch.Size([1, 512])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97571333",
   "metadata": {},
   "source": [
    "# construct loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c5d323b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(),lr=0.01,momentum=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7b7374",
   "metadata": {},
   "source": [
    "# Training cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4b6b1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,device):\n",
    "    running_loss = 0.0\n",
    "    for branch_idx,data in enumerate(train_loader,0):\n",
    "        images,targets=data\n",
    "        images, targets = images.to(device),targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs=net(images)\n",
    "        loss=criterion(outputs,targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "        if branch_idx % 299 ==0:\n",
    "            print('[%d,%5d] loss:%.3f' % ((epoch+1,branch_idx+1,running_loss/300)))\n",
    "            running_loss=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "02bad577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(device):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad(): #停止跟踪历史记录\n",
    "        for data in test_loader:\n",
    "            images, targets = data\n",
    "            images, targets = images.to(device),targets.to(device)\n",
    "            _,predicted = torch.max(net(images),dim=1)\n",
    "            total+=images.size(0)\n",
    "            correct+=(predicted==targets).sum().item()\n",
    "    print('Accuracy on test set is %d %%'%(correct/total*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "683216f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    1] loss:0.008\n",
      "[1,  300] loss:0.770\n",
      "[1,  599] loss:0.260\n",
      "[1,  898] loss:0.180\n",
      "Accuracy on test set is 96 %\n",
      "[2,    1] loss:0.000\n",
      "[2,  300] loss:0.138\n",
      "[2,  599] loss:0.120\n",
      "[2,  898] loss:0.110\n",
      "Accuracy on test set is 97 %\n",
      "[3,    1] loss:0.000\n",
      "[3,  300] loss:0.096\n",
      "[3,  599] loss:0.087\n",
      "[3,  898] loss:0.089\n",
      "Accuracy on test set is 97 %\n",
      "[4,    1] loss:0.000\n",
      "[4,  300] loss:0.072\n",
      "[4,  599] loss:0.074\n",
      "[4,  898] loss:0.070\n",
      "Accuracy on test set is 98 %\n",
      "[5,    1] loss:0.000\n",
      "[5,  300] loss:0.064\n",
      "[5,  599] loss:0.061\n",
      "[5,  898] loss:0.064\n",
      "Accuracy on test set is 98 %\n",
      "[6,    1] loss:0.000\n",
      "[6,  300] loss:0.057\n",
      "[6,  599] loss:0.055\n",
      "[6,  898] loss:0.052\n",
      "Accuracy on test set is 98 %\n",
      "[7,    1] loss:0.000\n",
      "[7,  300] loss:0.056\n",
      "[7,  599] loss:0.052\n",
      "[7,  898] loss:0.045\n",
      "Accuracy on test set is 98 %\n",
      "[8,    1] loss:0.000\n",
      "[8,  300] loss:0.047\n",
      "[8,  599] loss:0.044\n",
      "[8,  898] loss:0.049\n",
      "Accuracy on test set is 98 %\n",
      "[9,    1] loss:0.000\n",
      "[9,  300] loss:0.042\n",
      "[9,  599] loss:0.045\n",
      "[9,  898] loss:0.041\n",
      "Accuracy on test set is 98 %\n",
      "[10,    1] loss:0.000\n",
      "[10,  300] loss:0.038\n",
      "[10,  599] loss:0.043\n",
      "[10,  898] loss:0.038\n",
      "Accuracy on test set is 98 %\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "net.to(device)\n",
    "for epoch in range(10):\n",
    "    train(epoch,device)\n",
    "    test(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b0f2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "pytorch_visdom",
   "language": "python",
   "name": "pytorch_visdom3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
